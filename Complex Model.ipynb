{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training scheme\n",
    "#### (1) train denoising auto encoder model using all data including train and test data\n",
    "#### (2) from the weights of denoising auto encoder model, finetune to predict targets such as reactivity\n",
    "\n",
    "### rough network architecture\n",
    "#### inputs -> conv1ds -> aggregation of neighborhoods -> multi head attention -> aggregation of neighborhoods -> multi head attention -> conv1d -> predict\n",
    "#### this architecture was inspired by https://www.kaggle.com/cpmpml/graph-transfomer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pretrain_dir = None # model dir for resuming training. if None, train from scrach\n",
    "\n",
    "one_fold = False # if True, train model at only first fold. use if you try a new idea quickly.\n",
    "run_test = False # if True, use small data. you can check whether this code run or not\n",
    "denoise = True # if True, use train data whose signal_to_noise > 1\n",
    "\n",
    "ae_epochs = 20 # epoch of training of denoising auto encoder\n",
    "ae_epochs_each = 5 # epoch of training of denoising auto encoder each time. \n",
    "                   # I use train data (seqlen = 107) and private test data (seqlen = 130) for auto encoder training.\n",
    "                   # I dont know how to easily fit keras model to use both of different shape data simultaneously, \n",
    "                   # so I call fit function several times. \n",
    "ae_batch_size = 32\n",
    "\n",
    "epochs_list = [30, 10, 3, 3, 5, 5]\n",
    "batch_size_list = [8, 16, 32, 64, 128, 256] \n",
    "\n",
    "## copy pretrain model to working dir\n",
    "import shutil\n",
    "import glob\n",
    "if pretrain_dir is not None:\n",
    "    for d in glob.glob(pretrain_dir + \"*\"):\n",
    "        shutil.copy(d, \".\")\n",
    "    \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data = pd.read_json(\"../data/train.json\",lines=True)\n",
    "if denoise:\n",
    "    data = data[data.signal_to_noise > 1].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 107, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "\n",
    "data_labels = []\n",
    "seq_len = data[\"seq_length\"].iloc[0]\n",
    "seq_len_target = data[\"seq_scored\"].iloc[0]\n",
    "ignore = -10000\n",
    "ignore_length = seq_len - seq_len_target\n",
    "for target in targets:\n",
    "    y = np.vstack(data[target])\n",
    "    dummy = np.zeros([y.shape[0], ignore_length]) + ignore\n",
    "    y = np.hstack([y, dummy])\n",
    "    data_labels.append(y)\n",
    "data_labels = np.stack(data_labels, axis = 2)\n",
    "data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, data_labels, test_size=.1, random_state=47, \n",
    "    stratify=data.SN_filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d20aee430c4ef2ab1f0e437bae09e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f973248acb7b4fc08cfafbe9a2a2804b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if run_test: ## to test \n",
    "    data = data[:30]\n",
    "\n",
    "As = []\n",
    "for id in tqdm(x_train[\"id\"]):\n",
    "    a = np.load(f\"../data/bpps/{id}.npy\")\n",
    "    As.append(a)\n",
    "As = np.array(As)\n",
    "As_pub = []\n",
    "for id in tqdm(x_test[\"id\"]):\n",
    "    a = np.load(f\"../data/bpps/{id}.npy\")\n",
    "    As_pub.append(a)\n",
    "As_pub = np.array(As_pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1886, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>deg_error_Mg_pH10</th>\n",
       "      <th>deg_error_pH10</th>\n",
       "      <th>deg_error_Mg_50C</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1661</td>\n",
       "      <td>id_b4aa34fee</td>\n",
       "      <td>GGAAAGCAGCGCCGGAAGGCACAGCCGCAAAACUAAAGGCGAAAAA...</td>\n",
       "      <td>........(.(((....))).).(((((...(((...((((........</td>\n",
       "      <td>EEEEEEEESISSSHHHHSSSISMSSSSSIIISSSIIISSSSHHHHH...</td>\n",
       "      <td>3.974</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1917, 0.24550000000000002, 0.22060000000000...</td>\n",
       "      <td>[0.25730000000000003, 0.2838, 0.21030000000000...</td>\n",
       "      <td>[0.324, 0.3235, 0.21960000000000002, 0.158, 0....</td>\n",
       "      <td>[0.18130000000000002, 0.2024, 0.18630000000000...</td>\n",
       "      <td>[0.2751, 0.2983, 0.2523, 0.1961, 0.2083, 0.202...</td>\n",
       "      <td>[0.5057, 1.7747000000000002, 1.5566, 0.906, 1....</td>\n",
       "      <td>[0.9389000000000001, 1.7486000000000002, 0.941...</td>\n",
       "      <td>[1.9460000000000002, 3.1451000000000002, 1.271...</td>\n",
       "      <td>[0.3917, 1.1639, 1.0394, 0.5305, 0.67270000000...</td>\n",
       "      <td>[0.6966, 1.8341, 1.3003, 0.7393000000000001, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1951</td>\n",
       "      <td>id_d19174185</td>\n",
       "      <td>GGAAAUAUAAAUUUCAGCUUCACAUUCCUUUCGCAUUCGAAAGAAU...</td>\n",
       "      <td>............(((..((((.((((((((((.(((((....))))...</td>\n",
       "      <td>EEEEEEEEEEEESSSIISSSSBSSSSSSSSSSISSSSSHHHHSSSS...</td>\n",
       "      <td>3.317</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.2637, 0.35350000000000004, 0.24980000000000...</td>\n",
       "      <td>[0.44570000000000004, 0.5985, 0.3523, 0.3275, ...</td>\n",
       "      <td>[0.5332, 0.6131, 0.3215, 0.322, 0.3284, 0.3784...</td>\n",
       "      <td>[0.21150000000000002, 0.3528, 0.2285, 0.2427, ...</td>\n",
       "      <td>[0.39640000000000003, 0.517, 0.3624, 0.2995, 0...</td>\n",
       "      <td>[0.7349, 1.6002, 0.9375, 0.7302000000000001, 1...</td>\n",
       "      <td>[0.8748, 2.5291, 0.7826000000000001, 0.7193, 2...</td>\n",
       "      <td>[2.7114000000000003, 3.5916, 0.8818, 1.0267, 1...</td>\n",
       "      <td>[0.343, 1.6571, 0.7803, 1.0464, 1.3912, 1.5941...</td>\n",
       "      <td>[1.0008, 1.7982, 1.1282, 0.7133, 1.74460000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>273</td>\n",
       "      <td>id_1bd260b05</td>\n",
       "      <td>GGAAACGCAGCAGGCAGAUGACGCGGAAAACAUAGGAAAAACUAUG...</td>\n",
       "      <td>.....(((.((.(.((.(((.((((.....(((((......)))))...</td>\n",
       "      <td>EEEEESSSBSSBSISSISSSBSSSSIIIIISSSSSHHHHHHSSSSS...</td>\n",
       "      <td>4.740</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.2053, 0.25, 0.22080000000000002, 0.176, 0.1...</td>\n",
       "      <td>[0.28850000000000003, 0.3342, 0.2634, 0.204500...</td>\n",
       "      <td>[0.3164, 0.3764, 0.2298, 0.19690000000000002, ...</td>\n",
       "      <td>[0.1837, 0.2802, 0.19720000000000001, 0.1958, ...</td>\n",
       "      <td>[0.2155, 0.366, 0.29610000000000003, 0.2258, 0...</td>\n",
       "      <td>[0.8514, 1.3002, 1.4004, 0.9162, 0.1922, 0.104...</td>\n",
       "      <td>[0.7996000000000001, 1.2032, 0.874400000000000...</td>\n",
       "      <td>[1.9604, 2.5952, 1.0739, 0.877, 0.3819, 0.6940...</td>\n",
       "      <td>[0.501, 1.5292, 0.8887, 1.0166, 0.470400000000...</td>\n",
       "      <td>[0.3069, 1.5297, 1.4404, 0.8256, 0.2597, 0.503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>1492</td>\n",
       "      <td>id_a0fc45be8</td>\n",
       "      <td>GGAAAGCGCACGAGGCCGAUCGAGAAUGGAUUGCAGCGAGAGAGGC...</td>\n",
       "      <td>......(((.((.((((..((..(..((.....)).)..))..)))...</td>\n",
       "      <td>EEEEEESSSISSISSSSIISSIISIISSHHHHHSSISIISSIISSS...</td>\n",
       "      <td>7.068</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.14880000000000002, 0.1713, 0.1631, 0.1199, ...</td>\n",
       "      <td>[0.1993, 0.2436, 0.2044, 0.1346, 0.1024, 0.098...</td>\n",
       "      <td>[0.233, 0.2389, 0.16390000000000002, 0.1149, 0...</td>\n",
       "      <td>[0.14850000000000002, 0.2366, 0.1621, 0.108400...</td>\n",
       "      <td>[0.2056, 0.2429, 0.1832, 0.1279, 0.1254, 0.093...</td>\n",
       "      <td>[0.7467, 1.4459, 1.5955, 0.8522000000000001, 0...</td>\n",
       "      <td>[0.8696, 1.9521000000000002, 1.596, 0.6469, 0....</td>\n",
       "      <td>[2.1264, 2.9469000000000003, 1.4311, 0.6401, 0...</td>\n",
       "      <td>[0.5842, 3.1236, 1.5319, 0.6339, 0.4465, 0.237...</td>\n",
       "      <td>[1.0084, 2.2792, 1.3965, 0.6178, 0.6412, 0.285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>869</td>\n",
       "      <td>id_5a917f313</td>\n",
       "      <td>GGAAACGUACGGUACGGUUGUCGGUUAGGCAACUGCUGUCUGCAGA...</td>\n",
       "      <td>...............(.((((.((.((((((..(((((((....))...</td>\n",
       "      <td>EEEEEEEEEEEEEEESISSSSISSISSSSSSBBSSSSSSSHHHHSS...</td>\n",
       "      <td>1.891</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.363, 0.5069, 0.3811, 0.4199, 0.287000000000...</td>\n",
       "      <td>[0.5436, 0.7083, 0.6357, 0.42310000000000003, ...</td>\n",
       "      <td>[0.6141, 0.6917, 0.4786, 0.4057, 0.2313, 0.401...</td>\n",
       "      <td>[0.2614, 0.4813, 0.4828, 0.3547, 0.2636, 0.284...</td>\n",
       "      <td>[0.5109, 0.6109, 0.48660000000000003, 0.4445, ...</td>\n",
       "      <td>[0.337, 1.3322, 0.8707, 1.207, 0.4961000000000...</td>\n",
       "      <td>[0.4277, 1.3516, 1.4038, 0.4153, 0.0, 0.3008, ...</td>\n",
       "      <td>[1.0879, 1.6128, 0.9981000000000001, 0.4722, 0...</td>\n",
       "      <td>[-0.1558, 0.7852, 1.4011, 0.5535, 0.2865000000...</td>\n",
       "      <td>[0.4645, 0.9849, 1.0028, 0.6905, 0.34340000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index            id                                           sequence  \\\n",
       "1452   1661  id_b4aa34fee  GGAAAGCAGCGCCGGAAGGCACAGCCGCAAAACUAAAGGCGAAAAA...   \n",
       "1705   1951  id_d19174185  GGAAAUAUAAAUUUCAGCUUCACAUUCCUUUCGCAUUCGAAAGAAU...   \n",
       "242     273  id_1bd260b05  GGAAACGCAGCAGGCAGAUGACGCGGAAAACAUAGGAAAAACUAUG...   \n",
       "1303   1492  id_a0fc45be8  GGAAAGCGCACGAGGCCGAUCGAGAAUGGAUUGCAGCGAGAGAGGC...   \n",
       "764     869  id_5a917f313  GGAAACGUACGGUACGGUUGUCGGUUAGGCAACUGCUGUCUGCAGA...   \n",
       "\n",
       "                                              structure  \\\n",
       "1452  ........(.(((....))).).(((((...(((...((((........   \n",
       "1705  ............(((..((((.((((((((((.(((((....))))...   \n",
       "242   .....(((.((.(.((.(((.((((.....(((((......)))))...   \n",
       "1303  ......(((.((.((((..((..(..((.....)).)..))..)))...   \n",
       "764   ...............(.((((.((.((((((..(((((((....))...   \n",
       "\n",
       "                                    predicted_loop_type  signal_to_noise  \\\n",
       "1452  EEEEEEEESISSSHHHHSSSISMSSSSSIIISSSIIISSSSHHHHH...            3.974   \n",
       "1705  EEEEEEEEEEEESSSIISSSSBSSSSSSSSSSISSSSSHHHHSSSS...            3.317   \n",
       "242   EEEEESSSBSSBSISSISSSBSSSSIIIIISSSSSHHHHHHSSSSS...            4.740   \n",
       "1303  EEEEEESSSISSISSSSIISSIISIISSHHHHHSSISIISSIISSS...            7.068   \n",
       "764   EEEEEEEEEEEEEEESISSSSISSISSSSSSBBSSSSSSSHHHHSS...            1.891   \n",
       "\n",
       "      SN_filter  seq_length  seq_scored  \\\n",
       "1452          1         107          68   \n",
       "1705          1         107          68   \n",
       "242           1         107          68   \n",
       "1303          1         107          68   \n",
       "764           1         107          68   \n",
       "\n",
       "                                       reactivity_error  \\\n",
       "1452  [0.1917, 0.24550000000000002, 0.22060000000000...   \n",
       "1705  [0.2637, 0.35350000000000004, 0.24980000000000...   \n",
       "242   [0.2053, 0.25, 0.22080000000000002, 0.176, 0.1...   \n",
       "1303  [0.14880000000000002, 0.1713, 0.1631, 0.1199, ...   \n",
       "764   [0.363, 0.5069, 0.3811, 0.4199, 0.287000000000...   \n",
       "\n",
       "                                      deg_error_Mg_pH10  \\\n",
       "1452  [0.25730000000000003, 0.2838, 0.21030000000000...   \n",
       "1705  [0.44570000000000004, 0.5985, 0.3523, 0.3275, ...   \n",
       "242   [0.28850000000000003, 0.3342, 0.2634, 0.204500...   \n",
       "1303  [0.1993, 0.2436, 0.2044, 0.1346, 0.1024, 0.098...   \n",
       "764   [0.5436, 0.7083, 0.6357, 0.42310000000000003, ...   \n",
       "\n",
       "                                         deg_error_pH10  \\\n",
       "1452  [0.324, 0.3235, 0.21960000000000002, 0.158, 0....   \n",
       "1705  [0.5332, 0.6131, 0.3215, 0.322, 0.3284, 0.3784...   \n",
       "242   [0.3164, 0.3764, 0.2298, 0.19690000000000002, ...   \n",
       "1303  [0.233, 0.2389, 0.16390000000000002, 0.1149, 0...   \n",
       "764   [0.6141, 0.6917, 0.4786, 0.4057, 0.2313, 0.401...   \n",
       "\n",
       "                                       deg_error_Mg_50C  \\\n",
       "1452  [0.18130000000000002, 0.2024, 0.18630000000000...   \n",
       "1705  [0.21150000000000002, 0.3528, 0.2285, 0.2427, ...   \n",
       "242   [0.1837, 0.2802, 0.19720000000000001, 0.1958, ...   \n",
       "1303  [0.14850000000000002, 0.2366, 0.1621, 0.108400...   \n",
       "764   [0.2614, 0.4813, 0.4828, 0.3547, 0.2636, 0.284...   \n",
       "\n",
       "                                          deg_error_50C  \\\n",
       "1452  [0.2751, 0.2983, 0.2523, 0.1961, 0.2083, 0.202...   \n",
       "1705  [0.39640000000000003, 0.517, 0.3624, 0.2995, 0...   \n",
       "242   [0.2155, 0.366, 0.29610000000000003, 0.2258, 0...   \n",
       "1303  [0.2056, 0.2429, 0.1832, 0.1279, 0.1254, 0.093...   \n",
       "764   [0.5109, 0.6109, 0.48660000000000003, 0.4445, ...   \n",
       "\n",
       "                                             reactivity  \\\n",
       "1452  [0.5057, 1.7747000000000002, 1.5566, 0.906, 1....   \n",
       "1705  [0.7349, 1.6002, 0.9375, 0.7302000000000001, 1...   \n",
       "242   [0.8514, 1.3002, 1.4004, 0.9162, 0.1922, 0.104...   \n",
       "1303  [0.7467, 1.4459, 1.5955, 0.8522000000000001, 0...   \n",
       "764   [0.337, 1.3322, 0.8707, 1.207, 0.4961000000000...   \n",
       "\n",
       "                                            deg_Mg_pH10  \\\n",
       "1452  [0.9389000000000001, 1.7486000000000002, 0.941...   \n",
       "1705  [0.8748, 2.5291, 0.7826000000000001, 0.7193, 2...   \n",
       "242   [0.7996000000000001, 1.2032, 0.874400000000000...   \n",
       "1303  [0.8696, 1.9521000000000002, 1.596, 0.6469, 0....   \n",
       "764   [0.4277, 1.3516, 1.4038, 0.4153, 0.0, 0.3008, ...   \n",
       "\n",
       "                                               deg_pH10  \\\n",
       "1452  [1.9460000000000002, 3.1451000000000002, 1.271...   \n",
       "1705  [2.7114000000000003, 3.5916, 0.8818, 1.0267, 1...   \n",
       "242   [1.9604, 2.5952, 1.0739, 0.877, 0.3819, 0.6940...   \n",
       "1303  [2.1264, 2.9469000000000003, 1.4311, 0.6401, 0...   \n",
       "764   [1.0879, 1.6128, 0.9981000000000001, 0.4722, 0...   \n",
       "\n",
       "                                             deg_Mg_50C  \\\n",
       "1452  [0.3917, 1.1639, 1.0394, 0.5305, 0.67270000000...   \n",
       "1705  [0.343, 1.6571, 0.7803, 1.0464, 1.3912, 1.5941...   \n",
       "242   [0.501, 1.5292, 0.8887, 1.0166, 0.470400000000...   \n",
       "1303  [0.5842, 3.1236, 1.5319, 0.6339, 0.4465, 0.237...   \n",
       "764   [-0.1558, 0.7852, 1.4011, 0.5535, 0.2865000000...   \n",
       "\n",
       "                                                deg_50C  \n",
       "1452  [0.6966, 1.8341, 1.3003, 0.7393000000000001, 0...  \n",
       "1705  [1.0008, 1.7982, 1.1282, 0.7133, 1.74460000000...  \n",
       "242   [0.3069, 1.5297, 1.4404, 0.8256, 0.2597, 0.503...  \n",
       "1303  [1.0084, 2.2792, 1.3965, 0.6178, 0.6412, 0.285...  \n",
       "764   [0.4645, 0.9849, 1.0028, 0.6905, 0.34340000000...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## structure adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfe940ec38143e3908be4200abf0fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1886, 107, 107, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a572753ff81f47c1b7881169eb25ae96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(210, 107, 107, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_structure_adj(train):\n",
    "    ## get adjacent matrix from structure sequence\n",
    "    \n",
    "    ## here I calculate adjacent matrix of each base pair, \n",
    "    ## but eventually ignore difference of base pair and integrate into one matrix\n",
    "    Ss = []\n",
    "    for i in tqdm(range(len(train))):\n",
    "        seq_length = train[\"seq_length\"].iloc[i]\n",
    "        structure = train[\"structure\"].iloc[i]\n",
    "        sequence = train[\"sequence\"].iloc[i]\n",
    "\n",
    "        cue = []\n",
    "        a_structures = {\n",
    "            (\"A\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"C\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"A\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"C\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "        }\n",
    "        a_structure = np.zeros([seq_length, seq_length])\n",
    "        for i in range(seq_length):\n",
    "            if structure[i] == \"(\":\n",
    "                cue.append(i)\n",
    "            elif structure[i] == \")\":\n",
    "                start = cue.pop()\n",
    "#                 a_structure[start, i] = 1\n",
    "#                 a_structure[i, start] = 1\n",
    "                a_structures[(sequence[start], sequence[i])][start, i] = 1\n",
    "                a_structures[(sequence[i], sequence[start])][i, start] = 1\n",
    "        \n",
    "        a_strc = np.stack([a for a in a_structures.values()], axis = 2)\n",
    "        a_strc = np.sum(a_strc, axis = 2, keepdims = True)\n",
    "        Ss.append(a_strc)\n",
    "    \n",
    "    Ss = np.array(Ss)\n",
    "    print(Ss.shape)\n",
    "    return Ss\n",
    "Ss = get_structure_adj(x_train)\n",
    "Ss_pub = get_structure_adj(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distance adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1886, 107, 107, 3)\n",
      "(210, 107, 107, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_distance_matrix(As):\n",
    "    ## adjacent matrix based on distance on the sequence\n",
    "    ## D[i, j] = 1 / (abs(i - j) + 1) ** pow, pow = 1, 2, 4\n",
    "    \n",
    "    idx = np.arange(As.shape[1])\n",
    "    Ds = []\n",
    "    for i in range(len(idx)):\n",
    "        d = np.abs(idx[i] - idx)\n",
    "        Ds.append(d)\n",
    "\n",
    "    Ds = np.array(Ds) + 1\n",
    "    Ds = 1/Ds\n",
    "    Ds = Ds[None, :,:]\n",
    "    Ds = np.repeat(Ds, len(As), axis = 0)\n",
    "    \n",
    "    Dss = []\n",
    "    for i in [1, 2, 4]: \n",
    "        Dss.append(Ds ** i)\n",
    "    Ds = np.stack(Dss, axis = 3)\n",
    "    print(Ds.shape)\n",
    "    return Ds\n",
    "\n",
    "Ds = get_distance_matrix(As)\n",
    "Ds_pub = get_distance_matrix(As_pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1886, 107, 107, 5), (210, 107, 107, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## concat adjecent\n",
    "As = np.concatenate([As[:,:,:,None], Ss, Ds], axis = 3).astype(np.float32)\n",
    "As_pub = np.concatenate([As_pub[:,:,:,None], Ss_pub, Ds_pub], axis = 3).astype(np.float32)\n",
    "del Ss, Ds, Ss_pub, Ds_pub\n",
    "As.shape, As_pub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(1886, 107, 39)\n",
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(210, 107, 39)\n"
     ]
    }
   ],
   "source": [
    "## sequence\n",
    "def return_ohe(n, i):\n",
    "    tmp = [0] * n\n",
    "    tmp[i] = 1\n",
    "    return tmp\n",
    "\n",
    "def get_input(train):\n",
    "    ## get node features, which is one hot encoded\n",
    "    mapping = {}\n",
    "    vocab = [\"A\", \"G\", \"C\", \"U\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_node = np.stack(train[\"sequence\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "\n",
    "    mapping = {}\n",
    "    vocab = [\"S\", \"M\", \"I\", \"B\", \"H\", \"E\", \"X\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_loop = np.stack(train[\"predicted_loop_type\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    \n",
    "    mapping = {}\n",
    "    vocab = [\".\", \"(\", \")\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_structure = np.stack(train[\"structure\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    \n",
    "    \n",
    "    X_node = np.concatenate([X_node, X_loop], axis = 2)\n",
    "    \n",
    "    ## interaction\n",
    "    a = np.sum(X_node * (2 ** np.arange(X_node.shape[2])[None, None, :]), axis = 2)\n",
    "    vocab = sorted(set(a.flatten()))\n",
    "    print(vocab)\n",
    "    ohes = []\n",
    "    for v in vocab:\n",
    "        ohes.append(a == v)\n",
    "    ohes = np.stack(ohes, axis = 2)\n",
    "    X_node = np.concatenate([X_node, ohes], axis = 2).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    print(X_node.shape)\n",
    "    return X_node\n",
    "\n",
    "X_node = get_input(x_train)\n",
    "X_node_pub = get_input(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def mcrmse(t, p, seq_len_target = seq_len_target):\n",
    "    ## calculate mcrmse score by using numpy\n",
    "    t = t[:, :seq_len_target]\n",
    "    p = p[:, :seq_len_target]\n",
    "    \n",
    "    score = np.mean(np.sqrt(np.mean(np.mean((p - t) ** 2, axis = 1), axis = 0)))\n",
    "    return score\n",
    "\n",
    "def mcrmse_loss(t, y, seq_len_target = seq_len_target):\n",
    "    ## calculate mcrmse score by using tf\n",
    "    t = t[:, :seq_len_target]\n",
    "    y = y[:, :seq_len_target]\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.sqrt(tf.reduce_mean(tf.reduce_mean((t - y) ** 2, axis = 1), axis = 0)))\n",
    "    return loss\n",
    "\n",
    "def attention(x_inner, x_outer, n_factor, dropout):\n",
    "    x_Q =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_inner)\n",
    "    x_K =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_V =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_KT = L.Permute((2, 1))(x_K)\n",
    "    res = L.Lambda(lambda c: K.batch_dot(c[0], c[1]) / np.sqrt(n_factor))([x_Q, x_KT])\n",
    "#     res = tf.expand_dims(res, axis = 3)\n",
    "#     res = L.Conv2D(16, 3, 1, padding = \"same\", activation = \"relu\")(res)\n",
    "#     res = L.Conv2D(1, 3, 1, padding = \"same\", activation = \"relu\")(res)\n",
    "#     res = tf.squeeze(res, axis = 3)\n",
    "    att = L.Lambda(lambda c: K.softmax(c, axis=-1))(res)\n",
    "    att = L.Lambda(lambda c: K.batch_dot(c[0], c[1]))([att, x_V])\n",
    "    return att\n",
    "\n",
    "def multi_head_attention(x, y, n_factor, n_head, dropout):\n",
    "    if n_head == 1:\n",
    "        att = attention(x, y, n_factor, dropout)\n",
    "    else:\n",
    "        n_factor_head = n_factor // n_head\n",
    "        heads = [attention(x, y, n_factor_head, dropout) for i in range(n_head)]\n",
    "        att = L.Concatenate()(heads)\n",
    "        att = L.Dense(n_factor, \n",
    "                      kernel_initializer='glorot_uniform',\n",
    "                      bias_initializer='glorot_uniform',\n",
    "                     )(att)\n",
    "    x = L.Add()([x, att])\n",
    "    x = L.LayerNormalization()(x)\n",
    "    if dropout > 0:\n",
    "        x = L.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def res(x, unit, kernel = 3, rate = 0.1):\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "    return L.Add()([x, h])\n",
    "\n",
    "def forward(x, unit, kernel = 3, rate = 0.1):\n",
    "#     h = L.Dense(unit, None)(x)\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "#         h = tf.keras.activations.swish(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = res(h, unit, kernel, rate)\n",
    "    return h\n",
    "\n",
    "def adj_attn(x, adj, unit, n = 2, rate = 0.1):\n",
    "    x_a = x\n",
    "    x_as = []\n",
    "    for i in range(n):\n",
    "        x_a = forward(x_a, unit)\n",
    "        x_a = tf.matmul(adj, x_a) ## aggregate neighborhoods\n",
    "        x_as.append(x_a)\n",
    "    if n == 1:\n",
    "        x_a = x_as[0]\n",
    "    else:\n",
    "        x_a = L.Concatenate()(x_as)\n",
    "    x_a = forward(x_a, unit)\n",
    "    return x_a\n",
    "\n",
    "\n",
    "def get_base(config):\n",
    "    ## base model architecture \n",
    "    ## node, adj -> middle feature\n",
    "    \n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    adj_learned = L.Dense(1, \"relu\")(adj)\n",
    "    adj_all = L.Concatenate(axis = 3)([adj, adj_learned])\n",
    "        \n",
    "    xs = []\n",
    "    xs.append(node)\n",
    "    x1 = forward(node, 128, kernel = 3, rate = 0.0)\n",
    "    x2 = forward(x1, 64, kernel = 6, rate = 0.0)\n",
    "    x3 = forward(x2, 32, kernel = 15, rate = 0.0)\n",
    "    x4 = forward(x3, 16, kernel = 30, rate = 0.0)\n",
    "    x = L.Concatenate()([x1, x2, x3, x4])\n",
    "    \n",
    "    for unit in [64, 32]:\n",
    "        x_as = []\n",
    "        for i in range(adj_all.shape[3]):\n",
    "            x_a = adj_attn(x, adj_all[:, :, :, i], unit, rate = 0.0)\n",
    "            x_as.append(x_a)\n",
    "        x_c = forward(x, unit, kernel = 30)\n",
    "        \n",
    "        x = L.Concatenate()(x_as + [x_c])\n",
    "        x = forward(x, unit)\n",
    "        x = multi_head_attention(x, x, unit, 4, 0.0)\n",
    "        xs.append(x)\n",
    "        \n",
    "    x = L.Concatenate()(xs)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ae_model(base, config):\n",
    "    ## denoising auto encoder part\n",
    "    ## node, adj -> middle feature -> node\n",
    "    \n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "\n",
    "    x = base([L.SpatialDropout1D(0.3)(node), adj])\n",
    "    x = forward(x, 64, rate = 0.3)\n",
    "    p = L.Dense(X_node.shape[2], \"sigmoid\")(x)\n",
    "    \n",
    "    loss = - tf.reduce_mean(20 * node * tf.math.log(p + 1e-4) + (1 - node) * tf.math.log(1 - p + 1e-4))\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [loss])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = lambda t, y : y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(base, config):\n",
    "    ## regression part\n",
    "    ## node, adj -> middle feature -> prediction of targets\n",
    "    \n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    x = base([node, adj])\n",
    "    x = forward(x, 128, rate = 0.4)\n",
    "    x = L.Dense(5, None)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = mcrmse_loss)\n",
    "    return model\n",
    "\n",
    "def get_optimizer():\n",
    "#     sgd = tf.keras.optimizers.SGD(0.05, momentum = 0.9, nesterov=True)\n",
    "    adam = tf.optimizers.Adam()\n",
    "#     radam = tfa.optimizers.RectifiedAdam()\n",
    "#     lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n",
    "#     swa = tfa.optimizers.SWA(adam)\n",
    "    return adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here train denoising auto encoder model using all data\n",
    "\n",
    "config = {} ## not use now\n",
    "if ae_epochs > 0:\n",
    "    base = get_base(config)\n",
    "    ae_model = get_ae_model(base, config)\n",
    "    ## TODO : simultaneous train\n",
    "    for i in range(ae_epochs//ae_epochs_each):\n",
    "        print(f\"------ {i} ------\")\n",
    "        print(\"--- train ---\")\n",
    "        ae_model.fit([X_node, As], [X_node[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        print(\"--- public ---\")\n",
    "        ae_model.fit([X_node_pub, As_pub], [X_node_pub[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        print(\"--- private ---\")\n",
    "        ae_model.fit([X_node_pri, As_pri], [X_node_pri[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        gc.collect()\n",
    "    print(\"****** save ae model ******\")\n",
    "    base.save_weights(\"./base_ae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here train regression model from pretrain auto encoder model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(5, shuffle = True, random_state = 42)\n",
    "\n",
    "scores = []\n",
    "preds = np.zeros([len(X_node), X_node.shape[1], 5])\n",
    "for i, (tr_idx, va_idx) in enumerate(kfold.split(X_node, As)):\n",
    "    print(f\"------ fold {i} start -----\")\n",
    "    print(f\"------ fold {i} start -----\")\n",
    "    print(f\"------ fold {i} start -----\")\n",
    "    X_node_tr = X_node[tr_idx]\n",
    "    X_node_va = X_node[va_idx]\n",
    "    As_tr = As[tr_idx]\n",
    "    As_va = As[va_idx]\n",
    "    y_tr = y[tr_idx]\n",
    "    y_va = y[va_idx]\n",
    "    \n",
    "    base = get_base(config)\n",
    "    if ae_epochs > 0:\n",
    "        print(\"****** load ae model ******\")\n",
    "        base.load_weights(\"./base_ae\")\n",
    "    model = get_model(base, config)\n",
    "    if pretrain_dir is not None:\n",
    "        d = f\"./model{i}\"\n",
    "        print(f\"--- load from {d} ---\")\n",
    "        model.load_weights(d)\n",
    "    for epochs, batch_size in zip(epochs_list, batch_size_list):\n",
    "        print(f\"epochs : {epochs}, batch_size : {batch_size}\")\n",
    "        model.fit([X_node_tr, As_tr], [y_tr],\n",
    "                  validation_data=([X_node_va, As_va], [y_va]),\n",
    "                  epochs = epochs,\n",
    "                  batch_size = batch_size, validation_freq = 3)\n",
    "        \n",
    "    model.save_weights(f\"./model{i}\")\n",
    "    p = model.predict([X_node_va, As_va])\n",
    "    scores.append(mcrmse(y_va, p))\n",
    "    print(f\"fold {i}: mcrmse {scores[-1]}\")\n",
    "    preds[va_idx] = p\n",
    "    if one_fold:\n",
    "        break\n",
    "        \n",
    "pd.to_pickle(preds, \"oof.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pub = 0\n",
    "p_pri = 0\n",
    "for i in range(5):\n",
    "    model.load_weights(f\"./model{i}\")\n",
    "    p_pub += model.predict([X_node_pub, As_pub]) / 5\n",
    "    p_pri += model.predict([X_node_pri, As_pri]) / 5\n",
    "    if one_fold:\n",
    "        p_pub *= 5\n",
    "        p_pri *= 5\n",
    "        break\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    test_pub[target] = [list(p_pub[k, :, i]) for k in range(p_pub.shape[0])]\n",
    "    test_pri[target] = [list(p_pri[k, :, i]) for k in range(p_pri.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ls = []\n",
    "for df, preds in [(test_pub, p_pub), (test_pri, p_pri)]:\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "\n",
    "        single_df = pd.DataFrame(single_pred, columns=targets)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "        preds_ls.append(single_df)\n",
    "\n",
    "preds_df = pd.concat(preds_ls)\n",
    "preds_df.to_csv(\"submission.csv\", index = False)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
